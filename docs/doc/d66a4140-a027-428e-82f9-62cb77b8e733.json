{
    "summary": "The code imports libraries, defines functions for loading HDF5 data and handling compressed datasets. It creates visualizations, saves to specified paths, generates dataset names, visualizes joint positions and arm commands over time with custom labeling and y-axis limits, and includes subfunctions for plotting efforts data and saving plots.",
    "details": [
        {
            "comment": "This code imports necessary libraries and defines constants for joint names, state names, and base state names. It also includes a function to load data from HDF5 files, retrieving various variables including qpos, qvel, effort, action, and base_action. The code handles cases where the dataset may not exist or be compressed.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":0-33",
            "content": "import os\nimport numpy as np\nimport cv2\nimport h5py\nimport argparse\nimport matplotlib.pyplot as plt\nfrom constants import DT\nimport IPython\ne = IPython.embed\nJOINT_NAMES = [\"waist\", \"shoulder\", \"elbow\", \"forearm_roll\", \"wrist_angle\", \"wrist_rotate\"]\nSTATE_NAMES = JOINT_NAMES + [\"gripper\"]\nBASE_STATE_NAMES = [\"linear_vel\", \"angular_vel\"]\ndef load_hdf5(dataset_dir, dataset_name):\n    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n    if not os.path.isfile(dataset_path):\n        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n        exit()\n    with h5py.File(dataset_path, 'r') as root:\n        is_sim = root.attrs['sim']\n        compressed = root.attrs.get('compress', False)\n        qpos = root['/observations/qpos'][()]\n        qvel = root['/observations/qvel'][()]\n        if 'effort' in root.keys():\n            effort = root['/observations/effort'][()]\n        else:\n            effort = None\n        action = root['/action'][()]\n        base_action = root['/base_action'][()]\n        image_dict = dict()"
        },
        {
            "comment": "This code reads image data from a file, compresses it if necessary, and stores the uncompressed images in a dictionary. It takes episode index, dataset directory, and mirror flag as input parameters. If the mirror flag is true, it adds \"mirror_episode\" to the dataset name.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":34-59",
            "content": "        for cam_name in root[f'/observations/images/'].keys():\n            image_dict[cam_name] = root[f'/observations/images/{cam_name}'][()]\n        if compressed:\n            compress_len = root['/compress_len'][()]\n    if compressed:\n        for cam_id, cam_name in enumerate(image_dict.keys()):\n            # un-pad and uncompress\n            padded_compressed_image_list = image_dict[cam_name]\n            image_list = []\n            for frame_id, padded_compressed_image in enumerate(padded_compressed_image_list): # [:1000] to save memory\n                image_len = int(compress_len[cam_id, frame_id])\n                compressed_image = padded_compressed_image\n                image = cv2.imdecode(compressed_image, 1)\n                image_list.append(image)\n            image_dict[cam_name] = image_list\n    return qpos, qvel, effort, action, base_action, image_dict\ndef main(args):\n    dataset_dir = args['dataset_dir']\n    episode_idx = args['episode_idx']\n    ismirror = args['ismirror']\n    if ismirror:\n        dataset_name = f'mirror_episode_{episode_idx}'"
        },
        {
            "comment": "The code loads data from an HDF5 file, creates videos and images for visualization, and saves them to specified paths. If the dataset name is not provided, it generates one based on episode index. The code also defines a function to save videos using OpenCV's VideoWriter.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":60-79",
            "content": "    else:\n        dataset_name = f'episode_{episode_idx}'\n    qpos, qvel, effort, action, base_action, image_dict = load_hdf5(dataset_dir, dataset_name)\n    print('hdf5 loaded!!')\n    save_videos(image_dict, DT, video_path=os.path.join(dataset_dir, dataset_name + '_video.mp4'))\n    visualize_joints(qpos, action, plot_path=os.path.join(dataset_dir, dataset_name + '_qpos.png'))\n    # visualize_single(effort, 'effort', plot_path=os.path.join(dataset_dir, dataset_name + '_effort.png'))\n    # visualize_single(action - qpos, 'tracking_error', plot_path=os.path.join(dataset_dir, dataset_name + '_error.png'))\n    visualize_base(base_action, plot_path=os.path.join(dataset_dir, dataset_name + '_base_action.png'))\n    # visualize_timestamp(t_list, dataset_path) # TODO addn timestamp back\ndef save_videos(video, dt, video_path=None):\n    if isinstance(video, list):\n        cam_names = list(video[0].keys())\n        h, w, _ = video[0][cam_names[0]].shape\n        w = w * len(cam_names)\n        fps = int(1/dt)\n        out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))"
        },
        {
            "comment": "This code concatenates images from multiple cameras into a single video, swaps the B and R channel colors, and saves it to the specified path. If the input is a dictionary of camera videos, it combines them along the width dimension.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":80-104",
            "content": "        for ts, image_dict in enumerate(video):\n            images = []\n            for cam_name in cam_names:\n                image = image_dict[cam_name]\n                image = image[:, :, [2, 1, 0]] # swap B and R channel\n                images.append(image)\n            images = np.concatenate(images, axis=1)\n            out.write(images)\n        out.release()\n        print(f'Saved video to: {video_path}')\n    elif isinstance(video, dict):\n        cam_names = list(video.keys())\n        all_cam_videos = []\n        for cam_name in cam_names:\n            all_cam_videos.append(video[cam_name])\n        all_cam_videos = np.concatenate(all_cam_videos, axis=2) # width dimension\n        n_frames, h, w, _ = all_cam_videos.shape\n        fps = int(1 / dt)\n        out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n        for t in range(n_frames):\n            image = all_cam_videos[t]\n            image = image[:, :, [2, 1, 0]]  # swap B and R channel\n            out.write(image)\n        out.release()"
        },
        {
            "comment": "This function visualizes joint positions and arm commands over time. It takes qpos_list and command_list as inputs, and optionally plot_path, ylim, and label_overwrite. The function plots joint state and arm command for each dimension in separate subplots. If label_overwrite is provided, it uses those labels; otherwise, it defaults to 'State' and 'Command'. It also allows setting a custom y-axis limit.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":105-137",
            "content": "        print(f'Saved video to: {video_path}')\ndef visualize_joints(qpos_list, command_list, plot_path=None, ylim=None, label_overwrite=None):\n    if label_overwrite:\n        label1, label2 = label_overwrite\n    else:\n        label1, label2 = 'State', 'Command'\n    qpos = np.array(qpos_list) # ts, dim\n    command = np.array(command_list)\n    num_ts, num_dim = qpos.shape\n    h, w = 2, num_dim\n    num_figs = num_dim\n    fig, axs = plt.subplots(num_figs, 1, figsize=(8, 2 * num_dim))\n    # plot joint state\n    all_names = [name + '_left' for name in STATE_NAMES] + [name + '_right' for name in STATE_NAMES]\n    for dim_idx in range(num_dim):\n        ax = axs[dim_idx]\n        ax.plot(qpos[:, dim_idx], label=label1)\n        ax.set_title(f'Joint {dim_idx}: {all_names[dim_idx]}')\n        ax.legend()\n    # plot arm command\n    for dim_idx in range(num_dim):\n        ax = axs[dim_idx]\n        ax.plot(command[:, dim_idx], label=label2)\n        ax.legend()\n    if ylim:\n        for dim_idx in range(num_dim):\n            ax = axs[dim_idx]"
        },
        {
            "comment": "The code defines two functions: `visualize_single` and `visualize_base`. The `visualize_single` function plots efforts data for a specific episode, while the `visualize_base` function plots base readings. Both functions save the resulting plot and close the plot window.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":138-171",
            "content": "            ax.set_ylim(ylim)\n    plt.tight_layout()\n    plt.savefig(plot_path)\n    print(f'Saved qpos plot to: {plot_path}')\n    plt.close()\ndef visualize_single(efforts_list, label, plot_path=None, ylim=None, label_overwrite=None):\n    efforts = np.array(efforts_list) # ts, dim\n    num_ts, num_dim = efforts.shape\n    h, w = 2, num_dim\n    num_figs = num_dim\n    fig, axs = plt.subplots(num_figs, 1, figsize=(w, h * num_figs))\n    # plot joint state\n    all_names = [name + '_left' for name in STATE_NAMES] + [name + '_right' for name in STATE_NAMES]\n    for dim_idx in range(num_dim):\n        ax = axs[dim_idx]\n        ax.plot(efforts[:, dim_idx], label=label)\n        ax.set_title(f'Joint {dim_idx}: {all_names[dim_idx]}')\n        ax.legend()\n    if ylim:\n        for dim_idx in range(num_dim):\n            ax = axs[dim_idx]\n            ax.set_ylim(ylim)\n    plt.tight_layout()\n    plt.savefig(plot_path)\n    print(f'Saved effort plot to: {plot_path}')\n    plt.close()\ndef visualize_base(readings, plot_path=None):\n    readings = np.array(readings) # ts, dim"
        },
        {
            "comment": "Code plots joint state readings and creates a visualization for each dimension, with smoothed versions of the data using different window sizes. The plot is saved to a specified path, and a message is printed confirming the save location. A function for timestamp visualization is also defined.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":172-200",
            "content": "    num_ts, num_dim = readings.shape\n    num_figs = num_dim\n    fig, axs = plt.subplots(num_figs, 1, figsize=(8, 2 * num_dim))\n    # plot joint state\n    all_names = BASE_STATE_NAMES\n    for dim_idx in range(num_dim):\n        ax = axs[dim_idx]\n        ax.plot(readings[:, dim_idx], label='raw')\n        ax.plot(np.convolve(readings[:, dim_idx], np.ones(20)/20, mode='same'), label='smoothed_20')\n        ax.plot(np.convolve(readings[:, dim_idx], np.ones(10)/10, mode='same'), label='smoothed_10')\n        ax.plot(np.convolve(readings[:, dim_idx], np.ones(5)/5, mode='same'), label='smoothed_5')\n        ax.set_title(f'Joint {dim_idx}: {all_names[dim_idx]}')\n        ax.legend()\n    # if ylim:\n    #     for dim_idx in range(num_dim):\n    #         ax = axs[dim_idx]\n    #         ax.set_ylim(ylim)\n    plt.tight_layout()\n    plt.savefig(plot_path)\n    print(f'Saved effort plot to: {plot_path}')\n    plt.close()\ndef visualize_timestamp(t_list, dataset_path):\n    plot_path = dataset_path.replace('.pkl', '_timestamp.png')\n    h, w = 4, 10"
        },
        {
            "comment": "The code generates a timestamp plot for camera frames. It processes the time-stamp list, creates two subplots - one for timestamps and another for delta time (dt). The timestamps are plotted against their corresponding timestep and time in seconds. The delta time is also plotted against timesteps. Finally, it saves the plot at a specified location and prints the file path.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/visualize_episodes.py\":201-230",
            "content": "    fig, axs = plt.subplots(2, 1, figsize=(w, h*2))\n    # process t_list\n    t_float = []\n    for secs, nsecs in t_list:\n        t_float.append(secs + nsecs * 10E-10)\n    t_float = np.array(t_float)\n    ax = axs[0]\n    ax.plot(np.arange(len(t_float)), t_float)\n    ax.set_title(f'Camera frame timestamps')\n    ax.set_xlabel('timestep')\n    ax.set_ylabel('time (sec)')\n    ax = axs[1]\n    ax.plot(np.arange(len(t_float)-1), t_float[:-1] - t_float[1:])\n    ax.set_title(f'dt')\n    ax.set_xlabel('timestep')\n    ax.set_ylabel('time (sec)')\n    plt.tight_layout()\n    plt.savefig(plot_path)\n    print(f'Saved timestamp plot to: {plot_path}')\n    plt.close()\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset_dir', action='store', type=str, help='Dataset dir.', required=True)\n    parser.add_argument('--episode_idx', action='store', type=int, help='Episode index.', required=False)\n    parser.add_argument('--ismirror', action='store_true')\n    main(vars(parser.parse_args()))"
        }
    ]
}