{
    "summary": "This code reads data, initializes an actuator network, processes input, predicts output, visualizes action angular values, simulates a real environment, measures wheel/tracer velocities, calculates FPS, and plots/saves linear & angular velocity figures with command line args.",
    "details": [
        {
            "comment": "The code is importing necessary libraries and defining a function called \"main\" which takes arguments for dataset directory, episode index, actuator network directory, history length, future length, and prediction length. It checks if the required dataset exists, then reads the dataset from a h5py file and assigns the action data to a variable named 'actions'.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_episodes.py\":0-31",
            "content": "import os\nimport h5py\nimport numpy as np\nfrom robot_utils import move_grippers, calibrate_linear_vel, smooth_base_action, postprocess_base_action\nimport argparse\nimport matplotlib.pyplot as plt\nfrom real_env import make_real_env\nfrom constants import JOINT_NAMES, PUPPET_GRIPPER_JOINT_OPEN, FPS\nimport time\nimport IPython\ne = IPython.embed\nSTATE_NAMES = JOINT_NAMES + [\"gripper\", 'left_finger', 'right_finger']\ndef main(args):\n    dataset_dir = args['dataset_dir']\n    episode_idx = args['episode_idx']\n    dataset_name = f'episode_{episode_idx}'\n    actuator_network_dir = args['actuator_network_dir']\n    history_len = args['history_len']\n    future_len = args['future_len']\n    prediction_len = args['prediction_len']\n    use_actuator_net = actuator_network_dir is not None\n    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n    if not os.path.isfile(dataset_path):\n        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n        exit()\n    with h5py.File(dataset_path, 'r') as root:\n        actions = root['/action'][()]"
        },
        {
            "comment": "The code is initializing an actuator network and loading its state from a checkpoint file. It also loads the actuator statistics from a separate pickle file. The observed speed is normalized using these statistics, and a lambda function is defined to unnormalize the commanded speeds.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_episodes.py\":32-52",
            "content": "        base_actions = root['/base_action'][()]\n    if use_actuator_net:\n        from train_actuator_network import ActuatorNetwork\n        import torch\n        import pickle\n        actuator_network = ActuatorNetwork(prediction_len)\n        actuator_network_path = os.path.join(actuator_network_dir, 'actuator_net_last.ckpt')\n        loading_status = actuator_network.load_state_dict(torch.load(actuator_network_path))\n        actuator_network.eval()\n        actuator_network.cuda()\n        print(f'Loaded actuator network from: {actuator_network_path}, {loading_status}')\n        actuator_stats_path  = os.path.join(actuator_network_dir, 'actuator_net_stats.pkl')\n        with open(actuator_stats_path, 'rb') as f:\n            actuator_stats = pickle.load(f)\n        norm_observed_speed = (base_actions - actuator_stats[\"observed_speed_mean\"]) / actuator_stats[\"observed_speed_std\"]\n        out_unnorm_fn = lambda x: (x * actuator_stats[\"commanded_speed_std\"]) + actuator_stats[\"commanded_speed_mean\"]\n        history_pad = np.zeros((history_len, 2))"
        },
        {
            "comment": "Code pads the input, concatenates it, and performs a prediction using an actuator network. The result is processed and plotted alongside the original action.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_episodes.py\":53-72",
            "content": "        future_pad = np.zeros((future_len, 2))\n        norm_observed_speed = np.concatenate([history_pad, norm_observed_speed, future_pad], axis=0)\n        episode_len = base_actions.shape[0]\n        assert(episode_len % prediction_len == 0)\n        processed_base_actions = []\n        for t in range(0, episode_len, prediction_len):\n            offset_start_ts = t + history_len\n            actuator_net_in = norm_observed_speed[offset_start_ts-history_len: offset_start_ts+future_len]\n            actuator_net_in = torch.from_numpy(actuator_net_in).float().unsqueeze(dim=0).cuda()\n            pred = actuator_network(actuator_net_in)\n            pred = pred.detach().cpu().numpy()[0]\n            processed_base_actions += out_unnorm_fn(pred).tolist()\n        processed_base_actions = np.array(processed_base_actions)\n        assert processed_base_actions.shape == base_actions.shape\n        plt.plot(base_actions[:, 0], label='action_linear')\n        plt.plot(processed_base_actions[:, 0], '--', label='processed_action_linear')"
        },
        {
            "comment": "This code plots the action angular values and processed action angular values, then simulates a real environment with base actions, collects observations on wheel and tracer velocities, and calculates average frames per second (FPS) for the simulation.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_episodes.py\":73-98",
            "content": "        plt.plot(base_actions[:, 1], label='action_angular')\n        plt.plot(processed_base_actions[:, 1], '--', label='processed_action_angular')\n        plt.plot()\n        plt.legend()\n        plt.show()\n    else:\n        # processed_base_actions = smooth_base_action(base_actions)\n        processed_base_actions = base_actions\n    env = make_real_env(init_node=True, setup_base=True)\n    env.reset()\n    obs_wheels = []\n    obs_tracer = []\n    time0 = time.time()\n    DT = 1 / FPS\n    for action, base_action in zip(actions, processed_base_actions):\n        time1 = time.time()\n        # base_action = calibrate_linear_vel(base_action, c=0.19)\n        # base_action = postprocess_base_action(base_action)\n        ts = env.step(action, base_action, get_tracer_vel=True)\n        obs_wheels.append(ts.observation['base_vel'])\n        obs_tracer.append(ts.observation['tracer_vel'])\n        time.sleep(max(0, DT - (time.time() - time1)))\n    print(f'Avg fps: {len(actions) / (time.time() - time0)}')\n    obs_wheels = np.array(obs_wheels)"
        },
        {
            "comment": "This code plots and saves two figures: 'replay_episodes_linear_vel.png' and 'replay_episodes_angular_vel.png'. It first plots linear and angular velocities of base, processed base, wheels, and tracer. After saving the linear figure, it opens both grippers. The script assumes the presence of a variable named 'env', which is likely an environment object. The user can specify the dataset directory using the command line argument '--dataset_dir'.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_episodes.py\":99-123",
            "content": "    obs_tracer = np.array(obs_tracer)\n    plt.plot(base_actions[:, 0], label='action_linear')\n    plt.plot(processed_base_actions[:, 0], '--', label='processed_action_linear')\n    plt.plot(obs_wheels[:, 0], '--', label='obs_wheels_linear')\n    plt.plot(obs_tracer[:, 0], '-.', label='obs_tracer_linear')\n    plt.plot()\n    plt.legend()\n    plt.savefig('replay_episodes_linear_vel.png', dpi=300)\n    plt.clf()\n    plt.plot(base_actions[:, 1], label='action_angular')\n    plt.plot(processed_base_actions[:, 1], '--', label='processed_action_angular')\n    plt.plot(obs_wheels[:, 1], '--', label='obs_wheels_angular')\n    plt.plot(obs_tracer[:, 1], '-.', label='obs_tracer_angular')\n    plt.plot()\n    plt.legend()\n    plt.savefig('replay_episodes_angular_vel.png', dpi=300)\n    move_grippers([env.puppet_bot_left, env.puppet_bot_right], [PUPPET_GRIPPER_JOINT_OPEN] * 2, move_time=0.5)  # open\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset_dir', action='store', type=str, help='Dataset dir.', required=True)"
        },
        {
            "comment": "This code snippet uses the argparse module to add command line arguments for episode index, actuator network directory, history length, future length, and prediction length. These options are stored in a dictionary and passed as arguments to the main function.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_episodes.py\":124-129",
            "content": "    parser.add_argument('--episode_idx', action='store', type=int, help='Episode index.', required=False)\n    parser.add_argument('--actuator_network_dir', action='store', type=str, help='actuator_network_dir', required=False)\n    parser.add_argument('--history_len', action='store', type=int)\n    parser.add_argument('--future_len', action='store', type=int)\n    parser.add_argument('--prediction_len', action='store', type=int)\n    main(vars(parser.parse_args()))"
        }
    ]
}