{
    "summary": "This code imports libraries, stores and replay datasets, smooths base_actions, tracks time, steps environment, appends observations to lists, generates plots, and saves smoothed data with \"_replayed.hdf5\" added.",
    "details": [
        {
            "comment": "The code imports necessary libraries and defines a function to store a new dataset. It checks if the output path already exists, loads an uncompressed dataset from input_dataset_path, creates a replayed dataset at output_dataset_path, and copies non-image data directly.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_and_record_episodes.py\":0-30",
            "content": "import os\nimport h5py\nimport numpy as np\nfrom robot_utils import move_grippers, calibrate_linear_vel, smooth_base_action, postprocess_base_action\nimport argparse\nimport matplotlib.pyplot as plt\nfrom real_env import make_real_env\nfrom constants import JOINT_NAMES, PUPPET_GRIPPER_JOINT_OPEN, fps\nimport time\nimport IPython\ne = IPython.embed\nSTATE_NAMES = JOINT_NAMES + [\"gripper\", 'left_finger', 'right_finger']\ndef store_new_dataset(input_dataset_path, output_dataset_path, obs_wheels, obs_tracer):\n    # Check if output path exists\n    if os.path.exists(output_dataset_path):\n        print(f\"The file {output_dataset_path} already exists. Exiting...\")\n        return\n    # Load the uncompressed dataset\n    with h5py.File(input_dataset_path, 'r') as infile:\n        # Create the replayed dataset\n        with h5py.File(output_dataset_path, 'w') as outfile:\n            outfile.attrs['sim'] = infile.attrs['sim']\n            outfile.attrs['compress'] = True\n            # Copy non-image data directly\n            for key in infile.keys():"
        },
        {
            "comment": "This code reads a dataset, replayed it, and saves it to a new path. It checks if the original dataset exists before proceeding. The main function takes in arguments for dataset directory and episode index, and creates new dataset paths. It opens the original dataset as a read-only HDF5 file, extracts action and base_action data, initializes an environment, resets it, and then saves the replayed dataset to a new path with the same name but appended with \"_replayed.hdf5\". Finally, it prints a message confirming the saved location of the replayed dataset.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_and_record_episodes.py\":31-59",
            "content": "                outfile.copy(infile[key], key)\n            max_timesteps = infile['action'].shape[0]\n            _ = outfile.create_dataset('obs_wheels', (max_timesteps, 2))\n            _ = outfile.create_dataset('obs_tracer', (max_timesteps, 2))\n            outfile['obs_wheels'][()] = obs_wheels\n            outfile['obs_tracer'][()] = obs_tracer\n    print(f\"Replayed dataset saved to {output_dataset_path}\")\ndef main(args):\n    dataset_dir = args['dataset_dir']\n    episode_idx = args['episode_idx']\n    dataset_name = f'episode_{episode_idx}'\n    dataset_path = os.path.join(dataset_dir, dataset_name + '.hdf5')\n    dataset_new_path = os.path.join(dataset_dir, dataset_name + '_replayed.hdf5')\n    if not os.path.isfile(dataset_path):\n        print(f'Dataset does not exist at \\n{dataset_path}\\n')\n        exit()\n    with h5py.File(dataset_path, 'r') as root:\n        actions = root['/action'][()]\n        base_actions = root['/base_action'][()]\n    env = make_real_env(init_node=True, setup_base=True)\n    env.reset()"
        },
        {
            "comment": "In this code block, the base_actions are smoothed and the obs_wheels and obs_tracer lists are initialized. Then, a for loop iterates over the apply_actions and apply_base_actions. The time1 variable is used to track execution time, and the env.step() function is called with both actions. The resulting observations (obs_wheels and obs_tracer) are appended to their respective lists. Finally, a plot is generated for visualization purposes using matplotlib.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_and_record_episodes.py\":60-86",
            "content": "    # base_actions = smooth_base_action(base_actions)\n    obs_wheels = []\n    obs_tracer = []\n    offset = 0\n    scale = 1\n    apply_actions = actions\n    apply_base_actions = base_actions[offset:] * scale\n    DT = 1 / fps\n    for action, base_action in zip(apply_actions, apply_base_actions):\n        time1 = time.time()\n        # base_action = calibrate_linear_vel(base_action, c=0.19)\n        # base_action = postprocess_base_action(base_action)\n        ts = env.step(action, base_action, get_tracer_vel=True)\n        obs_wheels.append(ts.observation['base_vel'])\n        obs_tracer.append(ts.observation['tracer_vel'])\n        time.sleep(max(0, DT - (time.time() - time1)))\n    obs_wheels = np.array(obs_wheels)\n    obs_tracer = np.array(obs_tracer)\n    store_new_dataset(dataset_path, dataset_new_path, obs_wheels, obs_tracer)\n    plt.plot(base_actions[:, 0], label='action_linear')\n    plt.plot(base_actions[:, 1], label='action_angular')\n    plt.plot(obs_wheels[:, 0], '--', label='obs_wheels_linear')\n    plt.plot(obs_wheels[:, 1], '--', label='obs_wheels_angular')"
        },
        {
            "comment": "This code plots and saves two observations from the tracer for linear and angular movements, then opens grippers. It takes dataset directory and episode index as arguments, and calls main function after parsing arguments.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/replay_and_record_episodes.py\":87-100",
            "content": "    plt.plot(obs_tracer[:, 0], '-.', label='obs_tracer_linear')\n    plt.plot(obs_tracer[:, 1], '-.', label='obs_tracer_angular')\n    plt.legend()\n    plt.savefig('replay_and_record_episodes_vel_debug.png', dpi=300)\n    move_grippers([env.puppet_bot_left, env.puppet_bot_right], [PUPPET_GRIPPER_JOINT_OPEN] * 2, move_time=0.5)  # open\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset_dir', action='store', type=str, help='Dataset dir.', required=True)\n    parser.add_argument('--episode_idx', action='store', type=int, help='Episode index.', required=False)\n    main(vars(parser.parse_args()))"
        }
    ]
}