{
    "summary": "This code defines a bi-manual manipulation class for real robots and a class for handling environments, including observation functions and movement control. It enables real-time visualization of bimanual teleoperation through joint poses.",
    "details": [
        {
            "comment": "This code imports necessary libraries and defines a class for a real robot bi-manual manipulation environment. It includes constants, functions from other modules, and interacts with robot hardware such as InterbotixManipulatorXS and DynamixelClient. The action space consists of the left arm's joint positions, gripper position normalized to 0 or 1 (close or open), and left gripper velocities. This code is likely used for controlling a robotic system with two arms and grippers in real-world scenarios.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":0-25",
            "content": "import time\nimport numpy as np\nimport collections\nimport matplotlib.pyplot as plt\nimport dm_env\nfrom pyquaternion import Quaternion\nfrom constants import DT, START_ARM_POSE, MASTER_GRIPPER_JOINT_NORMALIZE_FN, PUPPET_GRIPPER_JOINT_UNNORMALIZE_FN\nfrom constants import PUPPET_GRIPPER_POSITION_NORMALIZE_FN, PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN\nfrom constants import PUPPET_GRIPPER_JOINT_OPEN, PUPPET_GRIPPER_JOINT_CLOSE\nfrom aloha_scripts.robot_utils import Recorder, ImageRecorder\nfrom aloha_scripts.robot_utils import setup_master_bot, setup_puppet_bot, move_arms, move_grippers\nfrom interbotix_xs_modules.arm import InterbotixManipulatorXS\nfrom interbotix_xs_msgs.msg import JointSingleCommand\nimport pyrealsense2 as rs\nimport pyagxrobots\nfrom dynamixel_client import DynamixelClient\nimport IPython\ne = IPython.embed\nclass RealEnv:\n    \"\"\"\n    Environment for real robot bi-manual manipulation\n    Action space:      [left_arm_qpos (6),             # absolute joint position\n                        left_gripper_positions (1),    # normalized gripper position (0: close, 1: open)"
        },
        {
            "comment": "Observation space defined for a robot with left and right arm joint positions, velocities, and gripper positions and velocities.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":26-36",
            "content": "                        right_arm_qpos (6),            # absolute joint position\n                        right_gripper_positions (1),]  # normalized gripper position (0: close, 1: open)\n    Observation space: {\"qpos\": Concat[ left_arm_qpos (6),          # absolute joint position\n                                        left_gripper_position (1),  # normalized gripper position (0: close, 1: open)\n                                        right_arm_qpos (6),         # absolute joint position\n                                        right_gripper_qpos (1)]     # normalized gripper position (0: close, 1: open)\n                        \"qvel\": Concat[ left_arm_qvel (6),         # absolute joint velocity (rad)\n                                        left_gripper_velocity (1),  # normalized gripper velocity (pos: opening, neg: closing)\n                                        right_arm_qvel (6),         # absolute joint velocity (rad)\n                                        right_gripper_qvel (1)]     # normalized gripper velocity (pos: opening, neg: closing)"
        },
        {
            "comment": "This code initializes two InterbotixManipulatorXS objects, one for the left arm and one for the right arm. If setup_robots is True, it calls the setup_robots() method, and if setup_base is True, it calls the setup_base() method.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":37-54",
            "content": "                        \"images\": {\"cam_high\": (480x640x3),        # h, w, c, dtype='uint8'\n                                   \"cam_low\": (480x640x3),         # h, w, c, dtype='uint8'\n                                   \"cam_left_wrist\": (480x640x3),  # h, w, c, dtype='uint8'\n                                   \"cam_right_wrist\": (480x640x3)} # h, w, c, dtype='uint8'\n    \"\"\"\n    def __init__(self, init_node, setup_robots=True, setup_base=False):\n        self.puppet_bot_left = InterbotixManipulatorXS(robot_model=\"vx300s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                                       robot_name=f'puppet_left', init_node=init_node)\n        self.puppet_bot_right = InterbotixManipulatorXS(robot_model=\"vx300s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                                        robot_name=f'puppet_right', init_node=False)\n        if setup_robots:\n            self.setup_robots()\n        if setup_base:\n            self.setup_base()\n        # self.setup_t265()"
        },
        {
            "comment": "This code initializes various objects and sets up the environment for a robot. It configures the camera, wheels, base, and robots. The `setup_t265` method initializes a real sensor pipeline for the 265 camera, enabling pose stream for higher fps. The `setup_dxl` initializes a Dynamixel client for two wheels with specified port and diameter, and calculates wheel and base radii. The `setup_base` enables CAN communication on a TracerBase object for the robot's base. The `setup_robots` sets up two puppet bots. Finally, `get_qpos` is used to retrieve joint positions from the robot.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":55-82",
            "content": "        self.setup_dxl()\n        self.recorder_left = Recorder('left', init_node=False)\n        self.recorder_right = Recorder('right', init_node=False)\n        self.image_recorder = ImageRecorder(init_node=False)\n        self.gripper_command = JointSingleCommand(name=\"gripper\")\n    def setup_t265(self):\n        self.pipeline = rs.pipeline()\n        cfg = rs.config()\n        # if only pose stream is enabled, fps is higher (202 vs 30)\n        cfg.enable_stream(rs.stream.pose)\n        self.pipeline.start(cfg)\n    def setup_dxl(self):\n        self.dxl_client = DynamixelClient([1, 2], port='/dev/ttyDXL_wheels', lazy_connect=True)\n        self.wheel_r = 0.101 / 2  # 101 mm is the diameter\n        self.base_r = 0.622  # 622 mm is the distance between the two wheels\n    def setup_base(self):\n        self.tracer = pyagxrobots.pysdkugv.TracerBase()\n        self.tracer.EnableCAN()\n    def setup_robots(self):\n        setup_puppet_bot(self.puppet_bot_left)\n        setup_puppet_bot(self.puppet_bot_right)\n    def get_qpos(self):"
        },
        {
            "comment": "This code segment retrieves the joint positions, velocities, and efforts from two robotic arms. It separates the gripper position and velocity of each arm using specific normalization functions. The data is then concatenated for further processing or analysis.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":83-100",
            "content": "        left_qpos_raw = self.recorder_left.qpos\n        right_qpos_raw = self.recorder_right.qpos\n        left_arm_qpos = left_qpos_raw[:6]\n        right_arm_qpos = right_qpos_raw[:6]\n        left_gripper_qpos = [PUPPET_GRIPPER_POSITION_NORMALIZE_FN(left_qpos_raw[7])] # this is position not joint\n        right_gripper_qpos = [PUPPET_GRIPPER_POSITION_NORMALIZE_FN(right_qpos_raw[7])] # this is position not joint\n        return np.concatenate([left_arm_qpos, left_gripper_qpos, right_arm_qpos, right_gripper_qpos])\n    def get_qvel(self):\n        left_qvel_raw = self.recorder_left.qvel\n        right_qvel_raw = self.recorder_right.qvel\n        left_arm_qvel = left_qvel_raw[:6]\n        right_arm_qvel = right_qvel_raw[:6]\n        left_gripper_qvel = [PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN(left_qvel_raw[7])]\n        right_gripper_qvel = [PUPPET_GRIPPER_VELOCITY_NORMALIZE_FN(right_qvel_raw[7])]\n        return np.concatenate([left_arm_qvel, left_gripper_qvel, right_arm_qvel, right_gripper_qvel])\n    def get_effort(self):"
        },
        {
            "comment": "This code reads the left and right robot effort, converts them to a specified format, concatenates them, and returns the result. It also retrieves images and calculates the base velocity of the robot in terms of linear and angular velocities based on the robot's pose data.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":101-123",
            "content": "        left_effort_raw = self.recorder_left.effort\n        right_effort_raw = self.recorder_right.effort\n        left_robot_effort = left_effort_raw[:7]\n        right_robot_effort = right_effort_raw[:7]\n        return np.concatenate([left_robot_effort, right_robot_effort])\n    def get_images(self):\n        return self.image_recorder.get_images()\n    def get_base_vel_t265(self):\n        raise NotImplementedError\n        frames = self.pipeline.wait_for_frames()\n        pose_frame = frames.get_pose_frame()\n        pose = pose_frame.get_pose_data()\n        q1 = Quaternion(w=pose.rotation.w, x=pose.rotation.x, y=pose.rotation.y, z=pose.rotation.z)\n        rotation = -np.array(q1.yaw_pitch_roll)[0]\n        rotation_vec = np.array([np.cos(rotation), np.sin(rotation)])\n        linear_vel_vec = np.array([pose.velocity.z, pose.velocity.x])\n        is_forward = rotation_vec.dot(linear_vel_vec) > 0\n        base_linear_vel = np.sqrt(pose.velocity.z ** 2 + pose.velocity.x ** 2) * (1 if is_forward else -1)\n        base_angular_vel = pose.angular_velocity.y"
        },
        {
            "comment": "Code snippet from \"mobile-aloha/aloha_scripts/real_env.py\" contains functions for retrieving base velocity, tracer velocity, and setting gripper pose. The get_base_vel() function calculates the linear and angular velocities of the robot's base. The get_tracer_vel() function retrieves the linear and angular velocities of a tracer object. The set_gripper_pose() function sets the desired position of the left and right grippers, normalizing the positions if necessary.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":124-144",
            "content": "        return np.array([base_linear_vel, base_angular_vel])\n    def get_base_vel(self):\n        left_vel, right_vel = self.dxl_client.read_pos_vel_cur()[1]\n        right_vel = -right_vel # right wheel is inverted\n        base_linear_vel = (left_vel + right_vel) * self.wheel_r / 2\n        base_angular_vel = (right_vel - left_vel) * self.wheel_r / self.base_r\n        return np.array([base_linear_vel, base_angular_vel])\n    def get_tracer_vel(self):\n        linear_vel, angular_vel = self.tracer.GetLinearVelocity(), self.tracer.GetAngularVelocity()\n        return np.array([linear_vel, angular_vel])\n    def set_gripper_pose(self, left_gripper_desired_pos_normalized, right_gripper_desired_pos_normalized):\n        left_gripper_desired_joint = PUPPET_GRIPPER_JOINT_UNNORMALIZE_FN(left_gripper_desired_pos_normalized)\n        self.gripper_command.cmd = left_gripper_desired_joint\n        self.puppet_bot_left.gripper.core.pub_single.publish(self.gripper_command)\n        right_gripper_desired_joint = PUPPET_GRIPPER_JOINT_UNNORMALIZE_FN(right_gripper_desired_pos_normalized)"
        },
        {
            "comment": "This code appears to be part of a robotics application, specifically controlling the gripper and arm movements of a puppet bot. The `_reset_joints` function resets the arm joint positions, while the `_reset_gripper` function first opens and then closes the gripper. The `get_observation` function returns various observations such as joint positions, velocities, robot effort, and possibly camera images. There may be a missing line for getting the base velocity of the robot in relation to its environment (base_vel_t265).",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":145-163",
            "content": "        self.gripper_command.cmd = right_gripper_desired_joint\n        self.puppet_bot_right.gripper.core.pub_single.publish(self.gripper_command)\n    def _reset_joints(self):\n        reset_position = START_ARM_POSE[:6]\n        move_arms([self.puppet_bot_left, self.puppet_bot_right], [reset_position, reset_position], move_time=1)\n    def _reset_gripper(self):\n        \"\"\"Set to position mode and do position resets: first open then close. Then change back to PWM mode\"\"\"\n        move_grippers([self.puppet_bot_left, self.puppet_bot_right], [PUPPET_GRIPPER_JOINT_OPEN] * 2, move_time=0.5)\n        move_grippers([self.puppet_bot_left, self.puppet_bot_right], [PUPPET_GRIPPER_JOINT_CLOSE] * 2, move_time=1)\n    def get_observation(self, get_tracer_vel=False):\n        obs = collections.OrderedDict()\n        obs['qpos'] = self.get_qpos()\n        obs['qvel'] = self.get_qvel()\n        obs['effort'] = self.get_effort()\n        obs['images'] = self.get_images()\n        # obs['base_vel_t265'] = self.get_base_vel_t265()"
        },
        {
            "comment": "The code belongs to the \"real_env.py\" file in the \"mobile-aloha/aloha_scripts\" directory. It defines a class that handles the environment for a puppet robot, including functions for getting observations and resetting the environment. The 'get_observation' function returns a dictionary of observations such as base velocity and (optionally) tracer velocity. The 'get_reward' function always returns 0. The 'reset' function reboots the gripper motors and resets joints and grippers if not in fake mode. The 'step' function takes an action, splits it into left and right actions, sets joint positions for the puppet bot arms, and can also get observations or tracer velocity if specified.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":164-190",
            "content": "        obs['base_vel'] = self.get_base_vel()\n        if get_tracer_vel:\n            obs['tracer_vel'] = self.get_tracer_vel()\n        return obs\n    def get_reward(self):\n        return 0\n    def reset(self, fake=False):\n        if not fake:\n            # Reboot puppet robot gripper motors\n            self.puppet_bot_left.dxl.robot_reboot_motors(\"single\", \"gripper\", True)\n            self.puppet_bot_right.dxl.robot_reboot_motors(\"single\", \"gripper\", True)\n            self._reset_joints()\n            self._reset_gripper()\n        return dm_env.TimeStep(\n            step_type=dm_env.StepType.FIRST,\n            reward=self.get_reward(),\n            discount=None,\n            observation=self.get_observation())\n    def step(self, action, base_action=None, get_tracer_vel=False, get_obs=True):\n        state_len = int(len(action) / 2)\n        left_action = action[:state_len]\n        right_action = action[state_len:]\n        self.puppet_bot_left.arm.set_joint_positions(left_action[:6], blocking=False)\n        self.puppet_bot_right.arm.set_joint_positions(right_action[:6], blocking=False)"
        },
        {
            "comment": "The code snippet sets the gripper position and controls the robot's base movement using the provided actions. If a base action is given, it clips the linear and angular velocities to specified limits and updates the tracer's motion command. It then obtains observations (if needed) and returns a time step with the reward, discount, and observation. The get_action function initializes an action array for two arms and sets arm actions based on the provided master bot states.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":191-213",
            "content": "        self.set_gripper_pose(left_action[-1], right_action[-1])\n        if base_action is not None:\n            # linear_vel_limit = 1.5\n            # angular_vel_limit = 1.5\n            # base_action_linear = np.clip(base_action[0], -linear_vel_limit, linear_vel_limit)\n            # base_action_angular = np.clip(base_action[1], -angular_vel_limit, angular_vel_limit)\n            base_action_linear, base_action_angular = base_action\n            self.tracer.SetMotionCommand(linear_vel=base_action_linear, angular_vel=base_action_angular)\n        # time.sleep(DT)\n        if get_obs:\n            obs = self.get_observation(get_tracer_vel)\n        else:\n            obs = None\n        return dm_env.TimeStep(\n            step_type=dm_env.StepType.MID,\n            reward=self.get_reward(),\n            discount=None,\n            observation=obs)\ndef get_action(master_bot_left, master_bot_right):\n    action = np.zeros(14) # 6 joint + 1 gripper, for two arms\n    # Arm actions\n    action[:6] = master_bot_left.dxl.joint_states.position[:6]"
        },
        {
            "comment": "This code is from the \"real_env.py\" file in the \"mobile-aloha/aloha_scripts\" directory. It defines a function called make_real_env that creates an instance of RealEnv class using parameters like init_node, setup_robots, and setup_base. Another function, test_real_teleop, tests bimanual teleoperation by reading joint poses from both master arms and using them as actions to step the environment, which returns full observations including images. The onscreen_render variable determines whether the observations are shown on-screen, and render_cam specifies the camera used for observation. The code also defines the InterbotixManipulatorXS class, which represents a manipulator with an arm and a gripper.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":214-245",
            "content": "    action[7:7+6] = master_bot_right.dxl.joint_states.position[:6]\n    # Gripper actions\n    action[6] = MASTER_GRIPPER_JOINT_NORMALIZE_FN(master_bot_left.dxl.joint_states.position[6])\n    action[7+6] = MASTER_GRIPPER_JOINT_NORMALIZE_FN(master_bot_right.dxl.joint_states.position[6])\n    return action\n# def get_base_action():\ndef make_real_env(init_node, setup_robots=True, setup_base=False):\n    env = RealEnv(init_node, setup_robots, setup_base)\n    return env\ndef test_real_teleop():\n    \"\"\"\n    Test bimanual teleoperation and show image observations onscreen.\n    It first reads joint poses from both master arms.\n    Then use it as actions to step the environment.\n    The environment returns full observations including images.\n    An alternative approach is to have separate scripts for teleoperation and observation recording.\n    This script will result in higher fidelity (obs, action) pairs\n    \"\"\"\n    onscreen_render = True\n    render_cam = 'cam_left_wrist'\n    # source of data\n    master_bot_left = InterbotixManipulatorXS(robot_model=\"wx250s\", group_name=\"arm\", gripper_name=\"gripper\","
        },
        {
            "comment": "This code sets up a robotic manipulator and environment, resets the environment with fake initial state, runs a simulation loop for 1000 timesteps, visualizes the robot's actions in real-time (if onscreen_render is True), and finally calls the test_real_teleop() function if the script is run directly.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/real_env.py\":246-275",
            "content": "                                              robot_name=f'master_left', init_node=True)\n    master_bot_right = InterbotixManipulatorXS(robot_model=\"wx250s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                               robot_name=f'master_right', init_node=False)\n    setup_master_bot(master_bot_left)\n    setup_master_bot(master_bot_right)\n    # setup the environment\n    env = make_real_env(init_node=False)\n    ts = env.reset(fake=True)\n    episode = [ts]\n    # setup visualization\n    if onscreen_render:\n        ax = plt.subplot()\n        plt_img = ax.imshow(ts.observation['images'][render_cam])\n        plt.ion()\n    for t in range(1000):\n        action = get_action(master_bot_left, master_bot_right)\n        ts = env.step(action)\n        episode.append(ts)\n        if onscreen_render:\n            plt_img.set_data(ts.observation['images'][render_cam])\n            plt.pause(DT)\n        else:\n            time.sleep(DT)\nif __name__ == '__main__':\n    test_real_teleop()"
        }
    ]
}