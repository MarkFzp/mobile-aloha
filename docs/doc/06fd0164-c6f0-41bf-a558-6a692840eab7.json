{
    "summary": "This code manages four robots, sets modes and grippers, handles gripper current limit issues, initializes environment, turns off torque, prepares instances, collects data, calculates FPS, enables bots' torque, stores observation data, prepares image data for HDF5 storage, runs an episode capture task with indices and diagnostics calculations.",
    "details": [
        {
            "comment": "This code is part of a larger script that controls two master and two puppet robots in a demonstration. It starts by rebooting the gripper motors and setting the operating modes for all motors on the puppet robot to prepare for the demonstration. The opening ceremony function ensures all robots are ready before starting the demonstration.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":0-26",
            "content": "import os\nimport time\nimport h5py\nimport argparse\nimport h5py_cache\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2\nfrom constants import DT, START_ARM_POSE, TASK_CONFIGS, FPS\nfrom constants import MASTER_GRIPPER_JOINT_MID, PUPPET_GRIPPER_JOINT_CLOSE, PUPPET_GRIPPER_JOINT_OPEN\nfrom robot_utils import Recorder, ImageRecorder, get_arm_gripper_positions\nfrom robot_utils import move_arms, torque_on, torque_off, move_grippers\nfrom real_env import make_real_env, get_action\nfrom interbotix_xs_modules.arm import InterbotixManipulatorXS\nimport IPython\ne = IPython.embed\ndef opening_ceremony(master_bot_left, master_bot_right, puppet_bot_left, puppet_bot_right):\n    \"\"\" Move all 4 robots to a pose where it is easy to start demonstration \"\"\"\n    # reboot gripper motors, and set operating modes for all motors\n    puppet_bot_left.dxl.robot_reboot_motors(\"single\", \"gripper\", True)\n    puppet_bot_left.dxl.robot_set_operating_modes(\"group\", \"arm\", \"position\")\n    puppet_bot_left.dxl.robot_set_operating_modes(\"single\", \"gripper\", \"current_based_position\")"
        },
        {
            "comment": "This code sets the operating modes and activates motors for robotic arms, initializes gripper modes, and moves the arms to their starting positions. The comment suggests there is an unresolved issue with setting the current limit on one of the grippers.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":27-43",
            "content": "    master_bot_left.dxl.robot_set_operating_modes(\"group\", \"arm\", \"position\")\n    master_bot_left.dxl.robot_set_operating_modes(\"single\", \"gripper\", \"position\")\n    # puppet_bot_left.dxl.robot_set_motor_registers(\"single\", \"gripper\", 'current_limit', 1000) # TODO(tonyzhaozh) figure out how to set this limit\n    puppet_bot_right.dxl.robot_reboot_motors(\"single\", \"gripper\", True)\n    puppet_bot_right.dxl.robot_set_operating_modes(\"group\", \"arm\", \"position\")\n    puppet_bot_right.dxl.robot_set_operating_modes(\"single\", \"gripper\", \"current_based_position\")\n    master_bot_right.dxl.robot_set_operating_modes(\"group\", \"arm\", \"position\")\n    master_bot_right.dxl.robot_set_operating_modes(\"single\", \"gripper\", \"position\")\n    # puppet_bot_left.dxl.robot_set_motor_registers(\"single\", \"gripper\", 'current_limit', 1000) # TODO(tonyzhaozh) figure out how to set this limit\n    torque_on(puppet_bot_left)\n    torque_on(master_bot_left)\n    torque_on(puppet_bot_right)\n    torque_on(master_bot_right)\n    # move arms to starting position"
        },
        {
            "comment": "Moves the arms to a starting position, sets grippers to start position, enables gripper movement for master robot while disabling torque, prints message to close gripper, checks gripper positions until both are below a threshold, then exits loop.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":44-62",
            "content": "    start_arm_qpos = START_ARM_POSE[:6]\n    move_arms([master_bot_left, puppet_bot_left, master_bot_right, puppet_bot_right], [start_arm_qpos] * 4, move_time=1.5)\n    # move grippers to starting position\n    move_grippers([master_bot_left, puppet_bot_left, master_bot_right, puppet_bot_right], [MASTER_GRIPPER_JOINT_MID, PUPPET_GRIPPER_JOINT_CLOSE] * 2, move_time=0.5)\n    # press gripper to start data collection\n    # disable torque for only gripper joint of master robot to allow user movement\n    master_bot_left.dxl.robot_torque_enable(\"single\", \"gripper\", False)\n    master_bot_right.dxl.robot_torque_enable(\"single\", \"gripper\", False)\n    print(f'Close the gripper to start')\n    close_thresh = -1.4\n    pressed = False\n    while not pressed:\n        gripper_pos_left = get_arm_gripper_positions(master_bot_left)\n        gripper_pos_right = get_arm_gripper_positions(master_bot_right)\n        if (gripper_pos_left < close_thresh) and (gripper_pos_right < close_thresh):\n            pressed = True\n        time.sleep(DT/10)"
        },
        {
            "comment": "This code snippet initializes the environment and robots for capturing one episode of data. It first turns off torque for both master bots, prints the dataset name, creates two InterbotixManipulatorXS instances for left and right master bots, and sets up a real environment without nodes or setup robots. It then checks if the specified dataset directory exists and creates it if not. If the dataset file already exists and overwrite is set to False, it prints a hint and exits.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":63-84",
            "content": "    torque_off(master_bot_left)\n    torque_off(master_bot_right)\n    print(f'Started!')\ndef capture_one_episode(dt, max_timesteps, camera_names, dataset_dir, dataset_name, overwrite):\n    print(f'Dataset name: {dataset_name}')\n    # source of data\n    master_bot_left = InterbotixManipulatorXS(robot_model=\"wx250s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                              robot_name=f'master_left', init_node=True)\n    master_bot_right = InterbotixManipulatorXS(robot_model=\"wx250s\", group_name=\"arm\", gripper_name=\"gripper\",\n                                               robot_name=f'master_right', init_node=False)\n    env = make_real_env(init_node=False, setup_robots=False)\n    # saving dataset\n    if not os.path.isdir(dataset_dir):\n        os.makedirs(dataset_dir)\n    dataset_path = os.path.join(dataset_dir, dataset_name)\n    if os.path.isfile(dataset_path) and not overwrite:\n        print(f'Dataset already exist at \\n{dataset_path}\\nHint: set overwrite to True.')\n        exit()"
        },
        {
            "comment": "This code sets up the environment for data collection, performs an \"opening_ceremony\" to position robots and waits until the gripper is closed. It collects data for a specific number of timesteps, calculates average FPS, enables torque on master bots, and opens puppet grippers.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":86-113",
            "content": "    # move all 4 robots to a starting pose where it is easy to start teleoperation, then wait till both gripper closed\n    opening_ceremony(master_bot_left, master_bot_right, env.puppet_bot_left, env.puppet_bot_right)\n    # Data collection\n    ts = env.reset(fake=True)\n    timesteps = [ts]\n    actions = []\n    actual_dt_history = []\n    time0 = time.time()\n    DT = 1 / FPS\n    for t in tqdm(range(max_timesteps)):\n        t0 = time.time() #\n        action = get_action(master_bot_left, master_bot_right)\n        t1 = time.time() #\n        ts = env.step(action)\n        t2 = time.time() #\n        timesteps.append(ts)\n        actions.append(action)\n        actual_dt_history.append([t0, t1, t2])\n        time.sleep(max(0, DT - (time.time() - t0)))\n    print(f'Avg fps: {max_timesteps / (time.time() - time0)}')\n    # Torque on both master bots\n    torque_on(master_bot_left)\n    torque_on(master_bot_right)\n    # Open puppet grippers\n    env.puppet_bot_left.dxl.robot_set_operating_modes(\"single\", \"gripper\", \"position\")\n    env.puppet_bot_right.dxl.robot_set_operating_modes(\"single\", \"gripper\", \"position\")"
        },
        {
            "comment": "The code starts by moving grippers to an open position and checks the frequency mean of dt_history. If it's below 30, it prints a message and returns False. Then, for each timestep, the code creates a data dictionary with observation types (qpos, qvel, effort), action, base_action, and various camera images as keys.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":114-145",
            "content": "    move_grippers([env.puppet_bot_left, env.puppet_bot_right], [PUPPET_GRIPPER_JOINT_OPEN] * 2, move_time=0.5)\n    freq_mean = print_dt_diagnosis(actual_dt_history)\n    if freq_mean < 30:\n        print(f'\\n\\nfreq_mean is {freq_mean}, lower than 30, re-collecting... \\n\\n\\n\\n')\n        return False\n    \"\"\"\n    For each timestep:\n    observations\n    - images\n        - cam_high          (480, 640, 3) 'uint8'\n        - cam_low           (480, 640, 3) 'uint8'\n        - cam_left_wrist    (480, 640, 3) 'uint8'\n        - cam_right_wrist   (480, 640, 3) 'uint8'\n    - qpos                  (14,)         'float64'\n    - qvel                  (14,)         'float64'\n    action                  (14,)         'float64'\n    base_action             (2,)          'float64'\n    \"\"\"\n    data_dict = {\n        '/observations/qpos': [],\n        '/observations/qvel': [],\n        '/observations/effort': [],\n        '/action': [],\n        '/base_action': [],\n        # '/base_action_t265': [],\n    }\n    for cam_name in camera_names:\n        data_dict[f'/observations/images/{cam_name}'] = []"
        },
        {
            "comment": "The code reads actions from a list and corresponding timesteps, appending observation data such as qpos, qvel, effort, base action, and images to a dictionary. It does not plot /base_action vs /base_action_t265 but provides the structure for doing so if needed.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":147-164",
            "content": "    # len(action): max_timesteps, len(time_steps): max_timesteps + 1\n    while actions:\n        action = actions.pop(0)\n        ts = timesteps.pop(0)\n        data_dict['/observations/qpos'].append(ts.observation['qpos'])\n        data_dict['/observations/qvel'].append(ts.observation['qvel'])\n        data_dict['/observations/effort'].append(ts.observation['effort'])\n        data_dict['/action'].append(action)\n        data_dict['/base_action'].append(ts.observation['base_vel'])\n        # data_dict['/base_action_t265'].append(ts.observation['base_vel_t265'])\n        for cam_name in camera_names:\n            data_dict[f'/observations/images/{cam_name}'].append(ts.observation['images'][cam_name])\n    # plot /base_action vs /base_action_t265\n    # import matplotlib.pyplot as plt\n    # plt.plot(np.array(data_dict['/base_action'])[:, 0], label='base_action_linear')\n    # plt.plot(np.array(data_dict['/base_action'])[:, 1], label='base_action_angular')\n    # plt.plot(np.array(data_dict['/base_action_t265'])[:, 0], '--', label='base_action_t265_linear')"
        },
        {
            "comment": "This code is compressing images from a data dictionary using JPEG compression with a quality level of 50. It calculates the size of each compressed image and stores it in the same dictionary, overwriting the original images. The time taken for compression is also recorded.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":165-188",
            "content": "    # plt.plot(np.array(data_dict['/base_action_t265'])[:, 1], '--', label='base_action_t265_angular')\n    # plt.legend()\n    # plt.savefig('record_episodes_vel_debug.png', dpi=300)\n    COMPRESS = True\n    if COMPRESS:\n        # JPEG compression\n        t0 = time.time()\n        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 50] # tried as low as 20, seems fine\n        compressed_len = []\n        for cam_name in camera_names:\n            image_list = data_dict[f'/observations/images/{cam_name}']\n            compressed_list = []\n            compressed_len.append([])\n            for image in image_list:\n                result, encoded_image = cv2.imencode('.jpg', image, encode_param) # 0.02 sec # cv2.imdecode(encoded_image, 1)\n                compressed_list.append(encoded_image)\n                compressed_len[-1].append(len(encoded_image))\n            data_dict[f'/observations/images/{cam_name}'] = compressed_list\n        print(f'compression: {time.time() - t0:.2f}s')\n        # pad so it has same length\n        t0 = time.time()"
        },
        {
            "comment": "This code pads the compressed image data to a maximum length, then creates and saves an HDF5 file with observation groups including image groups for each camera. This prepares the data for saving to disk in an efficient format.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":189-209",
            "content": "        compressed_len = np.array(compressed_len)\n        padded_size = compressed_len.max()\n        for cam_name in camera_names:\n            compressed_image_list = data_dict[f'/observations/images/{cam_name}']\n            padded_compressed_image_list = []\n            for compressed_image in compressed_image_list:\n                padded_compressed_image = np.zeros(padded_size, dtype='uint8')\n                image_len = len(compressed_image)\n                padded_compressed_image[:image_len] = compressed_image\n                padded_compressed_image_list.append(padded_compressed_image)\n            data_dict[f'/observations/images/{cam_name}'] = padded_compressed_image_list\n        print(f'padding: {time.time() - t0:.2f}s')\n    # HDF5\n    t0 = time.time()\n    with h5py.File(dataset_path + '.hdf5', 'w', rdcc_nbytes=1024**2*2) as root:\n        root.attrs['sim'] = False\n        root.attrs['compress'] = COMPRESS\n        obs = root.create_group('observations')\n        image = obs.create_group('images')\n        for cam_name in camera_names:"
        },
        {
            "comment": "This code creates datasets for image data, qpos, qvel, effort, and action. It also creates a compress_len dataset if COMPRESS is True. The code then populates the created datasets with corresponding data from data_dict and prints the time taken to save the file.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":210-230",
            "content": "            if COMPRESS:\n                _ = image.create_dataset(cam_name, (max_timesteps, padded_size), dtype='uint8',\n                                         chunks=(1, padded_size), )\n            else:\n                _ = image.create_dataset(cam_name, (max_timesteps, 480, 640, 3), dtype='uint8',\n                                         chunks=(1, 480, 640, 3), )\n        _ = obs.create_dataset('qpos', (max_timesteps, 14))\n        _ = obs.create_dataset('qvel', (max_timesteps, 14))\n        _ = obs.create_dataset('effort', (max_timesteps, 14))\n        _ = root.create_dataset('action', (max_timesteps, 14))\n        _ = root.create_dataset('base_action', (max_timesteps, 2))\n        # _ = root.create_dataset('base_action_t265', (max_timesteps, 2))\n        for name, array in data_dict.items():\n            root[name][...] = array\n        if COMPRESS:\n            _ = root.create_dataset('compress_len', (len(camera_names), max_timesteps))\n            root['/compress_len'][...] = compressed_len\n    print(f'Saving: {time.time() - t0:.1f} secs')"
        },
        {
            "comment": "The function `main` runs an episode capture task repeatedly until it successfully captures a healthy episode. It uses the `get_auto_index` function to automatically assign an index to the dataset if no episode index is provided. The captured episodes are saved in the specified dataset directory with a naming convention \"episode_N\" where N represents the index of the episode.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":232-262",
            "content": "    return True\ndef main(args):\n    task_config = TASK_CONFIGS[args['task_name']]\n    dataset_dir = task_config['dataset_dir']\n    max_timesteps = task_config['episode_len']\n    camera_names = task_config['camera_names']\n    if args['episode_idx'] is not None:\n        episode_idx = args['episode_idx']\n    else:\n        episode_idx = get_auto_index(dataset_dir)\n    overwrite = True\n    dataset_name = f'episode_{episode_idx}'\n    print(dataset_name + '\\n')\n    while True:\n        is_healthy = capture_one_episode(DT, max_timesteps, camera_names, dataset_dir, dataset_name, overwrite)\n        if is_healthy:\n            break\ndef get_auto_index(dataset_dir, dataset_name_prefix = '', data_suffix = 'hdf5'):\n    max_idx = 1000\n    if not os.path.isdir(dataset_dir):\n        os.makedirs(dataset_dir)\n    for i in range(max_idx+1):\n        if not os.path.isfile(os.path.join(dataset_dir, f'{dataset_name_prefix}episode_{i}.{data_suffix}')):\n            return i\n    raise Exception(f\"Error getting auto index, or more than {max_idx} episodes\")"
        },
        {
            "comment": "The code defines a function `print_dt_diagnosis` that calculates average frequency, mean action time, and mean environment step time from a given array of data. It also includes the `debug()` function which enters into an infinite loop and continuously prints diagnostics using the `Recorder` and `ImageRecorder` classes. The main part of the code uses argparse to accept task name and episode index as arguments.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":265-289",
            "content": "def print_dt_diagnosis(actual_dt_history):\n    actual_dt_history = np.array(actual_dt_history)\n    get_action_time = actual_dt_history[:, 1] - actual_dt_history[:, 0]\n    step_env_time = actual_dt_history[:, 2] - actual_dt_history[:, 1]\n    total_time = actual_dt_history[:, 2] - actual_dt_history[:, 0]\n    dt_mean = np.mean(total_time)\n    dt_std = np.std(total_time)\n    freq_mean = 1 / dt_mean\n    print(f'Avg freq: {freq_mean:.2f} Get action: {np.mean(get_action_time):.3f} Step env: {np.mean(step_env_time):.3f}')\n    return freq_mean\ndef debug():\n    print(f'====== Debug mode ======')\n    recorder = Recorder('right', is_debug=True)\n    image_recorder = ImageRecorder(init_node=False, is_debug=True)\n    while True:\n        time.sleep(1)\n        recorder.print_diagnostics()\n        image_recorder.print_diagnostics()\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--task_name', action='store', type=str, help='Task name.', required=True)\n    parser.add_argument('--episode_idx', action='store', type=int, help='Episode index.', default=None, required=False)"
        },
        {
            "comment": "This code is calling the main function with the arguments parsed by the parser.parse_args() method, and then it is in a TODO section which means it needs further implementation or attention.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/record_episodes.py\":290-291",
            "content": "    main(vars(parser.parse_args())) # TODO\n    # debug()"
        }
    ]
}