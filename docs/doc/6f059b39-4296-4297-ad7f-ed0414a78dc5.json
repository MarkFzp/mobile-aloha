{
    "summary": "This code imports libraries, processes RealSense2 data for robot control, calculates motion commands using PID controller, and visualizes angular velocity.",
    "details": [
        {
            "comment": "This code imports necessary libraries, reads data from an HDF5 file, and plots action and observation values. It also sets up a RealSense2 pipeline for robot control and enables the CAN stream.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/test.py\":0-47",
            "content": "#!/usr/bin/env python\n# coding: utf-8\n# In[1]:\nimport h5py\nimport matplotlib.pyplot as plt\nwith h5py.File('/home/mobile-aloha/data/aloha_mobile_fork/episode_19_replayed.hdf5', 'r') as f:\n    obs_wheels = f['obs_wheels'][:]\n    obs_tracer = f['obs_tracer'][:]\n    base_actions = f['base_action'][:]\n    plt.plot(base_actions[:, 0], label='action_linear')\n    plt.plot(base_actions[:, 1], label='action_angular')\n    plt.plot(obs_wheels[:, 0], '--', label='obs_wheels_linear')\n    plt.plot(obs_wheels[:, 1], '--', label='obs_wheels_angular')\n    plt.plot(obs_tracer[:, 0], '-.', label='obs_tracer_linear')\n    plt.plot(obs_tracer[:, 1], '-.', label='obs_tracer_angular')\n    plt.legend()\n    plt.show()\n# In[23]:\nimport pyrealsense2 as rs\nfrom pyquaternion import Quaternion\nimport numpy as np\nnp.set_printoptions(precision=3, suppress=True)\n# In[22]:\nimport pyagxrobots\ntracer = pyagxrobots.pysdkugv.TracerBase()\ntracer.EnableCAN()\n# In[24]:\npipeline = rs.pipeline()\ncfg = rs.config()\n# if only pose stream is enabled, fps is higher (202 vs 30)"
        },
        {
            "comment": "This code initializes a pose stream, starts the pipeline, and then continuously waits for frames. For each frame, it extracts the pose data, calculates rotation, linear velocity vector, base linear velocity, and base angular velocity. The motion command is set based on these calculated values. Finally, a plot is created showing the relationship between angular velocity commands and time.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/test.py\":48-75",
            "content": "cfg.enable_stream(rs.stream.pose)\npipeline.start(cfg)\n# In[41]:\nimport time\nset_vel = 0.05\nl = []\nfor _ in range(400):\n    frames = pipeline.wait_for_frames()\n    pose_frame = frames.get_pose_frame()\n    pose = pose_frame.get_pose_data()\n    q1 = Quaternion(w=pose.rotation.w, x=pose.rotation.x, y=pose.rotation.y, z=pose.rotation.z)\n    rotation = -np.array(q1.yaw_pitch_roll)[0]\n    rotation_vec = np.array([np.cos(rotation), np.sin(rotation)])\n    linear_vel_vec = np.array([pose.velocity.z, pose.velocity.x])\n    is_forward = rotation_vec.dot(linear_vel_vec) > 0\n    base_linear_vel = np.sqrt(pose.velocity.z ** 2 + pose.velocity.x ** 2) * (1 if is_forward else -1)\n    base_angular_vel = pose.angular_velocity.y\n    # print(rotation * 180 / np.pi, pose.angular_velocity.y, linear_vel_vec, is_forward, base_linear_vel)\n    # print(base_angular_vel)\n    l.append(base_angular_vel)\n    tracer.SetMotionCommand(linear_vel=0, angular_vel=set_vel)\n    time.sleep(0.02)\nfrom matplotlib import pyplot as plt\nplt.title(f'angular velocity cmd {set_vel}')"
        },
        {
            "comment": "This code snippet involves various steps for data processing and visualization. First, it plots angular velocity and saves it as a PNG image. Then, it uses a PID controller to determine an action based on the input. The code also retrieves pose data from frames, including translation and rotation, three times in a loop. Afterwards, it converts quaternion rotation values to yaw, pitch, and roll angles using Euler angles.",
            "location": "\"/media/root/Prima/works/mobile-aloha/docs/src/aloha_scripts/test.py\":76-131",
            "content": "plt.plot([set_vel] * len(l), linestyle='--', color='red')\nplt.plot(l)\nplt.savefig(f'angular_velocity_{set_vel}.png')\n# In[10]:\nfrom simple_pid import PID\npid = PID(1, 0.1, 0.05, setpoint=np.array([2,2]))\naction = pid(np.array([0., 0.]))\naction\n# In[6]:\nframes = pipeline.wait_for_frames()\npose_frame = frames.get_pose_frame()\npose = pose_frame.get_pose_data()\npose.translation, pose.rotation\n# In[4]:\nframes = pipeline.wait_for_frames()\npose_frame = frames.get_pose_frame()\npose = pose_frame.get_pose_data()\npose.translation, pose.rotation\n# In[5]:\nframes = pipeline.wait_for_frames()\npose_frame = frames.get_pose_frame()\npose = pose_frame.get_pose_data()\npose.translation, pose.rotation\n# In[49]:\nq1 = Quaternion(w=pose.rotation.w, x=pose.rotation.x, y=pose.rotation.y, z=pose.rotation.z)\nnp.array(q1.yaw_pitch_roll) * 180 / np.pi\n# In[10]:\nq1 = Quaternion(w=pose.rotation.w, x=pose.rotation.x, y=pose.rotation.y, z=pose.rotation.z)\nnp.array(q1.yaw_pitch_roll) * 180 / np.pi\n# In[ ]:"
        }
    ]
}